PDF 文件信息
==================================================
文件名: 07.pdf
标题: Microsoft Word - 1-10.doc
作者: gong40
创建者: PScript5.dll Version 5.2.2
生产者: Acrobat Distiller 7.0 (Windows)
总页数: 9

==================================================

文字内容
==================================================

=== 第 1 页 ===
48 第7章  进程调度：介绍   
 第第77章章    进进程程调调度度：：介介绍绍  
现在，运行进程的底层机制（ mechanism ）（如上下文切换）应该清楚了。如果还不清
楚，请往回翻一两章，再次阅读这些工作原理 的描述。然而，我们还不知道操作系统调度
程序采用的上层策略（ policy）。接下来会介绍一系列的调度策略（ sheduling policy ，有时称
为discipline ），它们是许多聪明又努力的人在过去这些年里开发的。  
事实上，调度的起源早于计算机系统。早期调 度策略取自于操作管理领域，并应用于
计算机。对于这个事实不必惊讶：装配线以及 许多人类活动也需要调度，而且许多关注点
是一样的，包括像激光一样清楚的对效率的渴望。因此，我们的问题如下。  
 
关键问题：如何开发调度策略  
我们该如何开发一个考虑调度策略的基本框架？ 什么是关键假设？哪些指标非常重要？哪些基本
方法已经在早期的系统中使用？  
 
7.1  工作负载假设 
探讨可能的策略范围之前，我们先做一些简化 假设。这些假设与系统中运行的进程有
关，有时候统称为工作负载（ workload ）。确定工作负载是构建调度策略的关键部分。工作
负载了解得越多，你的策略就越优化。  
我们这里做的工作负载的假设是不切实际的，但这没问题（目前） ，因为我们将来会放
宽这些假定，并最终开发出我们所谓的……（戏剧性的暂停）……  
一个完全可操作的调度准则（ a fully-operational scheduling discipline ）①。 
我们对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：  
1．每一个工作运行相同的时间。  
2．所有的工作同时到达。  
3．一旦开始，每个工作保持运行直到完成。  
4．所有的工作只是用 CPU（即它们不执行 IO操作）。 
5．每个工作的运行时间是已知的。  
我们说这些假设中许多是不现实的，但正如在奥威尔的《动物农场》 [045]中一些动物
比其他动物更平等，本章中的一些假设比其他 假设更不现实。特别是，你会很诧异每一个
工作的运行时间是已知的——这会让调度程序无所不知，尽管这样很了不起（也许） ，但最
近不太可能发生。  
                                   
① 讲这句话的方式和你讲“ A fully-operational Death Star. ”的方式一样。  

=== 第 2 页 ===
 7.3  先进先出（ FIFO） 49 
 7.2  调度指标 
除了做出工作负载假设之外，还需要一个东西 能让我们比较不同的调度策略：调度指
标。指标是我们用来衡量某些东西的东西，在进程调度中，有一些不同的指标是有意义的。  
现在，让我们简化一下生活，只用一个指标：周转时间（ turnaround time ）。任务的周转
时间定义为任务完成时间减去任务到达系统的时间。更正式的周转时间定义 T周转时间是：  
 T周转时间 = T完成时间−T到达时间   （7.1） 
因为我们假设所有的任务在同一时间到达，那么 T到达时间 = 0，因此 T周转时间 = T完成时间。随
着我们放宽上述假设，这个情况将改变。  
你应该注意到，周转时间是一个性能（ performance ）指标，这将是本章的首要关注点。
另一个有趣的指标是公平（ fairness），比如 Jian's Fairness Index[J91] 。性能和公平在调度系
统中往往是矛盾的。例如，调度程序可以优化 性能，但代价是以阻止一些任务运行，这就
降低了公平。这个难题也告诉我们，生活并不总是完美的。  
7.3  先进先出（FIFO） 
我们可以实现的最基本的算法，被称为先进先出（ First In First Out 或FIFO）调度，有
时候也称为先到先服务（ First Come First Served 或FCFS）。 
FIFO有一些积极的特性：它很简单，而且易于实现。而且，对于我们的假设，它的效
果很好。  
我们一起看一个简单的例子。想象一下， 3个工作 A、B和C在大致相同的时间（ T到达
时间 = 0）到达系统。因为 FIFO必须将某个工作放在前面，所以我们假设当它们都同时到达
时， A比B早一点点，然后 B比C早到达一点点。假设每个工作运行 10s。这些工作的平
均周转时间（ average turnaround time ）是多少？  
从图 7.1可以看出， A在10s时完成， B在20s时完成， C在30s时完成。因此，这 3
个任务的平均周转时间就是（ 10 + 20 + 30 ）/ 3 = 20。计算周转时间就这么简单。  
现在让我们放宽假设。具体来说，让我们放宽假设 1，因此不再认为每个任务的运行时
间相同。 FIFO表现如何？你可以构建什么样的工作负载来让 FIFO表现不好？  
（在继续往下读之前，请认真想一下……接着想……想到了么？！ ） 
你现在应该已经弄清楚了，但是以防万一，让 我们举个例子来说明不同长度的任务如
何导致 FIFO调度的问题。具体来说，我们再次假设 3个任务（ A、B和C），但这次 A运行
100s，而 B和C运行 10s。 
如图 7.2所示， A先运行 100s，B或C才有机会运行。因此，系统的平均周转时间是比
较高的：令人不快的 110s（（100 + 110 + 120 ）/ 3 = 110）。 

=== 第 3 页 ===
50 第7章  进程调度：介绍   
 
        
  
            图7.1  FIFO 的简单例子                      图7.2  为什么 FIFO没有那么好  
这个问题通常被称为护航效应（ convoy effect ）[B+79]，一些耗时较少的潜在资源消费
者被排在重量级的资源消费者之后。这个调度 方案可能让你想起在杂货店只有一个排队队
伍的时候，如果看到前面的人装满  3 辆购物车食品并且掏出了支票本，你感觉如何？这会
等很长时间①。 
 
提示： SJF原则  
最短任务优先代表一个总体调度原则，可以应用于所有系统，只要其中平均客户（或在我们案例中
的任务）周转时间很重要。想想你等待的任何队伍：如果有关的机构关心客户满意度，他们可能会考虑
到SJF。例如，大超市通常都有一个“零散购物”的通道，以确保仅购买几件东西的购物者，不会堵在
为即将到来的冬天而大量购物以做准备的家庭后面。  
 
那么我们该怎么办？如何开发一种更好的算法来处理任务实际运行时间不一样的场
景？先考虑一下，然后继续阅读。  
7.4  最短任务优先（SJF） 
事实证明，一个非常简单的方法解决了这个问 题。实际上这是从运筹学中借鉴的一个
想法 [C54，PV56]，然后应用到计算机系统的任务调度中。这个新的调度准则被称为最短任
务优先（ Shortest Job First ，SJF），该名称应该很容易记住，因为它完全描述了这个策略：
先运行最短的任务，然后是次短的任务，如此下去。  
我们用上面的例子，但以 SJF作为调度策略。图 7.3展示的是运行 A、B和C的结果。它
清楚地说明了为什么在考虑平均周转时间的情况下， SJF调度策略更好。仅通过在 A之前运行
B和C，SJF将平均周转时间从 110s降低到 50s（（10 + 20 + 120 ）/3 = 50）。 
事实上，考虑到所有工作同时到达的假设， 我们可以证明 SJF确实是一个最优 （optimal）
调度算法。但是，你是在上操作系统课，而不是研究理论，所以，这里允许没有证明。  
 
补充：抢占式调度程序  
在过去的批处理计算中，开发了一些非抢占式（ non-preemptive ）调度程序。这样的系统会将每项
工作做完，再考虑是否运行新工作。几乎所有现代化的调度程序都是抢占式的（ preemptive ），非常愿意
停止一个进程以运行另一个进程。这意味着调度程序采用了我们之前学习的机制。特别是调度程序可以
进行上下文切换，临时停止一个运行进程，并恢复（或启动）另一个进程。  
                                   
① 在这种情况下建在采取的在在：要么快要切换 到另一个队伍，要么要要要并放要。没没，要呼，要呼 。这样会变好的，不要不心。  

=== 第 4 页 ===
 7.5  最短完成时间优先（ STCF） 51 
 因此，我们找到了一个用 SJF进行调度的好方法，但是我们的假设仍然是不切实际的。
让我们放宽另一个假设。具体来说，我们可以针对假设 2，现在假设工作可以随时到达，而
不是同时到达。这导致了什么问题？  
（再次停下来想想……你在想吗？加油，你可以做到）  
在这里我们可以再次用一个例子来说明问题。现在，假设 A在t = 0时到达，且需要运
行100s。而 B和C在t = 10到达，且各需要运行 10s。用纯 SJF，我们可以得到如图 7.4所
示的调度。  
      
  
              图7.3  SJF 的简单例子                       图7.4  B和C晚到时的 SJF 
从图中可以看出，即使 B和C在A之后不久到达，它们仍然被迫等到 A完成，从而遭遇
同样的护航问题。这 3项工作的平均周转时间为 103.33s，即（ 100+（110−10）+（120−10））/3。 
7.5  最短完成时间优先（STCF） 
为了解决这个问题，需要放宽假设条件（工作必须保持运行直到完成） 。我们还需要调
度程序本身的一些机制。你可能已经猜到，鉴 于我们先前关于时钟中断和上下文切换的讨
论，当 B和C到达时，调度程序当然可以做其他事情：它可以抢占（ preempt）工作 A，并
决定运行另一个工作，或许稍后继续工作 A。根据我们的定义， SJF是一种非抢占式
（non-preemptive ）调度程序，因此存在上述问题。  
幸运的是，有一个调度程序完全就是这样做的：向 SJF添加抢占，称为最短完成时间优
先（Shortest Time-to-Completion First ，STCF）或抢占式最短作业优先 （Preemptive Shortest Job 
First ，PSJF）调度程序 [CK68]。每当新工作进入系统时，它就会确定剩余工作和新工作中，
谁的剩余时间最少，然后调度该工作。因此，在我们的例子中， STCF将抢占 A并运行 B和C以完
成。只有在它们完成后，才能调度 A的剩余时间。
图7.5展示了一个例子。  
结果是平均周转时间大大提高： 50s（……）。
和以前一样，考虑到我们的新假设， STCF可证明
是最优的。考虑到如果所有工作同时到达， SJF是
最优的，那么你应该能够看到 STCF的最优性是符合直觉的。  
 
图7.5  STCF 的简单例子  

=== 第 5 页 ===
52 第7章  进程调度：介绍   
 7.6  新度量指标：响应时间 
因此，如果我们知道任务长度，而且任务只使用 CPU，而我们唯一的衡量是周转时间，
STCF将是一个很好的策略。事实上，对于许多早期批处理系统，这些类型的调度算法有一
定的意义。然而，引入分时系统改变了这一切 。现在，用户将会坐在终端前面，同时也要
求系统的交互性好。因此，一个新的度量标准诞生了：响应时间（ response time ）。 
响应时间定义为从任务到达系统到首次运行的时间。更正式的定义是：  
 T响应时间 = T首次运行−T到达时间  （7.2） 
例如，如果我们有上面的调度（ A在时间 0到达， B和C在时间 10达到），每个作业
的响应时间如下：作业 A为0，B为0，C为10（平均： 3.33）。 
你可能会想， STCF和相关方法在响应时间上并不是很好。例如，如果 3个工作同时到
达，第三个工作必须等待前两个工作全部运行 后才能运行。这种方法虽然有很好的周转时
间，但对于响应时间和交互性是相当糟糕的。假设你在终端前输入，不得不等待 10s才能看
到系统的回应，只是因为其他一些工作已经在你之前被调度：你肯定不太开心。  
因此，我们还有另一个问题：如何构建对响应时间敏感的调度程序？  
7.7  轮转 
为了解决这个问题，我们将介绍一种 新的调度算法，通常被称为轮转（ Round-Robin ，
RR）调度 [K64]。基本思想很简单： RR在一个时间片 （time slice，有时称为调度量子， scheduling 
quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直
到结束。它反复执行，直到所有任务完成。因此， RR有时被称为时间切片（ time-slicing ）。
请注意，时间片长度必须是时钟中断周期的倍数。因此，如果时钟中断是每 10ms中断一次，
则时间片可以是 10ms、20ms或10ms的任何其他倍数。  
为了更详细地理解 RR，我们来看一个例子。 假设 3个任务 A、B和C在系统中同时到达，
并且它们都希望运行 5s。SJF调度程序必须运行完当前任务才可运行下一个任务（见图 7.6）。相
比之下， 1s时间片的 RR可以快要地循环工作（见图 7.7）。 
       
  
          图7.6  又是 SJF（响应时间不好）                 图7.7  轮转（响应时间好）  
RR的平均响应时间是： （0 + 1 + 2）/3 = 1; SJF 算法平均响应时间是： （0 + 5 + 10 ）/ 3 = 5。 
如你所见，时间片长度对于 RR是至关重要的。越短， RR在响应时间上表现越好。然

=== 第 6 页 ===
 7.7  轮转 53 
 而，时间片太短是有问题的：突然上下文切换 的成本将影响整体性能。因此，系统设计者
需要权衡时间片的长度，使其足够长，以便摊销（ amortize）上下文切换成本，而又不会使
系统不及时响应。  
 
提示：摊销可以减少成本  
当系统某些操作有固定成本时，通常会使用摊销技术（ amortization ）。通过减少成本的频度（即执
行较少次的操作） ，系统的总成本就会降低。 例如，如果时间片设置为 10ms，并且上下文切换时间为 1ms，
那么浪费大约 10%的时间用于上下文切换。如果要摊销这个成本，可以把时间片增加到 100ms。在这种
情况下，不到 1%的时间用于上下文切换，因此时间片带来的成本就被摊销了。  
 
请注意，上下文切换的成本不仅仅来自保存和 恢复少量寄存器的操作系统操作。程序
运行时，它们在 CPU高要缓存、 TLB、分支预测器和其他片上硬件中建立了大量的状态。
切换到另一个工作会导致此状态被刷新，且与 当前运行的作业相关的新状态被引入，这可
能导致显著的性能成本 [MB91]。 
如果响应时间是我们的唯一指标，那么带有合理时间片的 RR，就会是非常好的调度程
序。但是我们老朋友的周转时间呢？再来看看我们的例子。 A、B和C，每个运行时间为 5s，
同时到达， RR是具有（长） 1s时间片的调度程序。从图 7.7可以看出， A在13完成， B在
14，C在15，平均 14。相当可怕！   
这并不奇怪，如果周转时间是我们的指标，那么 RR确实是最糟糕的策略之一。直观地
说，这应该是有意义的： RR所做的正是延伸每个工作，只运行每个工作一小段时间，就转
向下一个工作。因为周转时间只关心作业何时完成， RR几乎是最差的，在很多情况下甚至
比简单的 FIFO更差。  
更一般地说，任何公平（ fair）的政策（如 RR），即在小规模的时间内将 CPU均匀分配
到活动进程之间，在周转时间这类指标上表现 不佳。事实上，这是固有的权衡：如果你愿
意不公平，你可以运行较短的工作直到完成， 但是要以响应时间为代价。如果你重视公平
性，则响应时间会较短，但会以周转时间为代 价。这种权衡在系统中很常见。你不能既拥
有你的蛋糕，又吃它①。 
我们开发了两种调度程序。第一种类型（ SJF、STCF）优化周转时间，但对响应时间不
利。第二种类型（ RR）优化响应时间，但对周转时间不利 。我们还有两个假设需要放宽：
假设 4（作业没有 I/O）和假设 5（每个作业的运行时间是已知的） 。接下来我们来解决这些
假设。  
 
提示：重叠可以提高利用率  
如有可能，重叠（ overlap）操作可以最大限度地提高系统的利用率。重叠在许多不同的领域很有用，
包括执行磁盘 I/O或将消息发送到远程机器时。在任何一种情况下，开始操作然后切换到其他工作都是
一个好主意，这也提高了系统的整体利用率和效率。  
                                   
① 这是一个这这人的说法，因为它应该是  “你不能保留你的蛋糕，又吃它  ”（这很明显，不是吗？） 。令人惊讶的是，这个
说法有一个维基百科页面。请自行查阅。 

=== 第 7 页 ===
54 第7章  进程调度：介绍   
 7 . 8   结 合I / O  
首先，我们将放宽假设 4：当然所有程序都执行 I/O。想象一下没有任何输入的程序：
每次都会产生相同的输出。设想一个没有输出的程序：它就像谚语所说的森林里倒下的树，没有人看到它。它的运行并不重要。  
调度程序显然要在工作发起 I/O请求时做出决定，因为当前正在运行的作业在 I/O期间
不会使用 CPU，它被阻塞等待 I/O完成。如果将 I/O发送到硬盘驱动器，则进程可能会被阻
塞几毫秒或更长时间，具体取决于驱动器当前的 I/O负载。因此，这时调度程序应该在 CPU
上安排另一项工作。  
调度程序还必须在 I/O完成时做出决定。发生这种情况时，会产生中断，操作系统运行
并将发出 I/O的进程从阻塞状态移回就绪状态。当然，它甚至可以决定在那个时候运行该项
工作。操作系统应该如何处理每项工作？  
为了更好地理解这个问题， 让我们假设有两项工作 A和B，每项工作需要 50ms的CPU
时间。但是，有一个明显的区别： A运行 10ms，然后发出 I/O请求（假设 I/O每个都需要
10ms），而 B只是使用 CPU 50ms ，不执行 I/O。调度程序先运行 A，然后运行 B（见图 7.8）。 
假设我们正在尝试构建 STCF调度程序。这样的调度程序应该如何考虑到这样的事实，
即A分解成 5个10ms子工作，而B仅仅是单个 50ms CPU 需求？显然， 仅仅运行一个工作，
然后运行另一个工作，而不考虑如何考虑 I/O是没有意义的。  
一种常见的方法是将 A的每个 10ms的子工作视为一项独立的工作。因此，当系统启动
时，它的选择是调度 10ms的A，还是 50ms的
B。对于 STCF，选择是明确的：选择较短的
一个，在这种情况下是 A。然后， A的工作已完成，只剩下 B，并开始运行。然后提交 A
的一个新子工作，它抢占 B并运行 10ms。这样做可以实现重叠（ overlap），一个进程在等
待另一个进程的 I/O完成时使用 CPU，系统因此得到更好的利用（见图 7.9）。 
           
  
            图7.8  资源的糟糕使用                      图7.9  重叠可以更好地使用资源  
这样我们就看到了调度程序可能如何结合 I/O。通过将每个 CPU突发作为一项工作，
调度程序确保“交互”的进程经常运行。当这些交互式作业正在执行 I/O时，其他 CPU密
集型作业将运行，从而更好地利用处理器。  
7.9  无法预知 
有了应对 I/O的基本方法，我们来到最后的假设：调度程序知道每个工作的长度。如前

=== 第 8 页 ===
 参考资料  55 
 所述，这可能是可以做出的最糟糕的假设。事 实上，在一个通用的操作系统中（比如我们
所关心的操作系统） ，操作系统通常对每个作业的长度知之甚少。因此，我们如何建立一个
没有这种先验知识的 SJF/STCF ？更进一步，我们如何能够将已经看到的一些想法与 RR调
度程序结合起来，以便响应时间也变得相当不没？  
7.10  小结 
我们介绍了调度的基本思想，并开发了两类方 法。第一类是运行最短的工作，从而优
化周转时间。第二类是交替运行所有工作，从 而优化响应时间。但很难做到“鱼与熊掌兼
得”，这是系统中常见的、固有的折中。我们也看到了如何将 I/O结合到场景中，但仍未解
决操作系统根本无法看到未来的问题。稍后， 我们将看到如何通过构建一个调度程序，利
用最近的历史预测未来，从而解决这个问题。 这个调度程序称为多级反馈队列，是第  8 章
的主题。  
参考资料 
[B+79]“The Convoy Phenomenon ” 
M. Blasgen, J. Gray, M. Mitoma, T. Price 
ACM Operating Systems Review, 13:2, April 1979 
也许是第一次在数据库和操作系统中提到护航效应。  
 
[C54]“Priority Assignment in Waiting Line Problems ” 
A. Cobham 
Journal of Operations Research, 2:70, pages 70–76, 1954 
关于使用 SJF方法调度修理机器的开创性论文。  
 
[K64]“Analysis of a Time-Shared Processor ”Leonard Kleinrock 
Naval Research Logistics Quarterly, 11:1, pages 59–73, March 1964 
该文可能是第一次提到轮转调度算法，当然是调度时分共享系统方法的最早分析之一。  
 
[CK68]“Computer Scheduling Methods and their Countermeasures ”Edward G. Coffman and Leonard Kleinrock 
AFIPS ’68 (Spring), April 1968 
一篇很好的早期文章，其中还分析了一些基本调度准则。  
 
[J91]“The Art of Computer Systems Performance Analysis: 
Techniques for Experimental Design, Measurement, Simulation, and Modeling ” 
R. Jain 
Interscience, New York, April 1991 
计算机系统测量的标准教科书。当然，这对你的库是一个很好的参考。  

=== 第 9 页 ===
56 第7章  进程调度：介绍   
  
[PV56]“Machine Repair as a Priority Waiting-Line Problem ”Thomas E. Phipps Jr. and W. R. Van V oorhis 
Operations Research, 4:1, pages 76–86, February 1956 
有关后续工作，概括了来自 Cobham最初工作的机器修理 SJF方法，也假定了在这样的环境中 STCF方法
的效用。具体来说， “有一些类型的修理工作，……涉及很多拆卸，地上满是螺母和螺栓，一旦进行就不应
该中断。在其他情况下，如果有一个或多个短工作可做，继续做长工作是不可取的（第 81页）。” 
 
[MB91]“The effect of context switches on cache performance ”Jeffrey C. Mogul and Anita Borg 
ASPLOS, 1991 
关于缓存性能如何受上下文切换影响的一项很好的研究 。在今天的系统中问题比较小，如今处理器每秒钟
发出数十亿条指令，但上下文切换仍发生在毫秒的时间级别。  
作业 
scheduler.py 这个程序允许你查看不同调度程序在调度指标（如响应时间、周转时间和
总等待时间）下的执行情况。详情请参阅 README 文件。  
问题 
1．使用 SJF和FIFO调度程序运行长度为 200的3个作业时，计算响应时间和周转
时间。  
2．现在做同样的事情，但有不同长度的作业，即 100、200和300。 
3．现在做同样的事情，但采用 RR调度程序，时间片为 1。 
4．对于什么类型的工作负载， SJF提供与 FIFO相同的周转时间？  
5．对于什么类型的工作负载和量子长度， SJF与RR提供相同的响应时间？  
6．随着工作长度的增加， SJF的响应时间会怎样？你能使用模拟程序来展示趋势吗？  
7．随着量子长度的增加， RR的响应时间会怎样？你能写出一个方程，计算给定 N个
工作时，最坏情况的响应时间吗？  
 

